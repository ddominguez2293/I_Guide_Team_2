{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "15511c55-4131-48b5-b486-154c8fe54c4c",
      "metadata": {
        "id": "15511c55-4131-48b5-b486-154c8fe54c4c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.ops import sigmoid_focal_loss\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "\n",
        "import pandas as pd\n",
        "import xarray as xr\n",
        "from skimage.util import view_as_windows\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "from tqdm import tqdm\n",
        "from scipy.ndimage import label\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63e72c3d",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "yJ8Bp9jZT9vv",
      "metadata": {
        "id": "yJ8Bp9jZT9vv"
      },
      "source": [
        "## Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "YM6AnzSzgqa_",
      "metadata": {
        "id": "YM6AnzSzgqa_"
      },
      "outputs": [],
      "source": [
        "class FocalLoss(torch.nn.Module):\n",
        "    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        focal_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
        "\n",
        "        if self.reduction == \"mean\":\n",
        "            return focal_loss.mean()\n",
        "        else:\n",
        "            return focal_loss.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "8169b5d7-8be9-4c08-8b38-84c265030be7",
      "metadata": {
        "id": "8169b5d7-8be9-4c08-8b38-84c265030be7"
      },
      "outputs": [],
      "source": [
        "class ConvLSTMCell(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, kernel_size=3):\n",
        "        super().__init__()\n",
        "        padding = kernel_size // 2\n",
        "        self.conv = nn.Conv2d(input_dim + hidden_dim, 4 * hidden_dim,\n",
        "                              kernel_size=kernel_size, padding=padding)\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x, h_prev, c_prev):\n",
        "        combined = torch.cat([x, h_prev], dim=1)\n",
        "        conv_output = self.conv(combined)\n",
        "        cc_i, cc_f, cc_o, cc_g = torch.chunk(conv_output, 4, dim=1)\n",
        "        i = torch.sigmoid(cc_i)\n",
        "        f = torch.sigmoid(cc_f)\n",
        "        o = torch.sigmoid(cc_o)\n",
        "        g = torch.tanh(cc_g)\n",
        "        c = f * c_prev + i * g\n",
        "        h = o * torch.tanh(c)\n",
        "        return h, c\n",
        "\n",
        "class SqueezeExcite(nn.Module):\n",
        "    def __init__(self, channel, reduction=4):\n",
        "        super().__init__()\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y\n",
        "\n",
        "class ResConvLSTM(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dim=32, patch_size=7, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.patch_size = patch_size\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.input_conv = nn.Conv2d(in_channels, hidden_dim, kernel_size=3, padding=1)\n",
        "        self.bn = nn.BatchNorm2d(hidden_dim)\n",
        "        self.se = SqueezeExcite(hidden_dim)\n",
        "\n",
        "        self.lstm_cell = ConvLSTMCell(hidden_dim, hidden_dim)\n",
        "\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.conv1x1 = nn.Conv2d(hidden_dim, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, T, H, W = x.size()\n",
        "        h, c = torch.zeros(B, self.hidden_dim, H, W, device=x.device), \\\n",
        "               torch.zeros(B, self.hidden_dim, H, W, device=x.device)\n",
        "\n",
        "        for t in range(T):\n",
        "            x_t = x[:, :, t, :, :]\n",
        "            x_t = self.input_conv(x_t)\n",
        "            x_t = self.bn(x_t)\n",
        "            x_t = F.relu(x_t)\n",
        "            x_t = self.se(x_t)\n",
        "\n",
        "            h, c = self.lstm_cell(x_t, h, c)\n",
        "\n",
        "        out = self.global_pool(h)\n",
        "        out = self.conv1x1(out)\n",
        "        out = out.view(B)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "LznYp8mvLEdA",
      "metadata": {
        "id": "LznYp8mvLEdA"
      },
      "outputs": [],
      "source": [
        "class ConvLSTMCell(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, kernel_size=3):\n",
        "        super().__init__()\n",
        "        padding = kernel_size // 2\n",
        "        self.conv = nn.Conv2d(input_dim + hidden_dim, 4 * hidden_dim,\n",
        "                              kernel_size=kernel_size, padding=padding)\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x, h_prev, c_prev):\n",
        "        combined = torch.cat([x, h_prev], dim=1)\n",
        "        conv_output = self.conv(combined)\n",
        "        cc_i, cc_f, cc_o, cc_g = torch.chunk(conv_output, 4, dim=1)\n",
        "        i = torch.sigmoid(cc_i)\n",
        "        f = torch.sigmoid(cc_f)\n",
        "        o = torch.sigmoid(cc_o)\n",
        "        g = torch.tanh(cc_g)\n",
        "        c = f * c_prev + i * g\n",
        "        h = o * torch.tanh(c)\n",
        "        return h, c\n",
        "\n",
        "class SqueezeExcite(nn.Module):\n",
        "    def __init__(self, channel, reduction=4):\n",
        "        super().__init__()\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super().__init__()\n",
        "        padding = kernel_size // 2\n",
        "        # takes max+avg pooled channels → 1-channel attention map\n",
        "        self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=padding)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # channel‐wise avg/max → each is (B,1,H,W)\n",
        "        avg = torch.mean(x, dim=1, keepdim=True) # general trend across all pixels\n",
        "        mx  = torch.max(x,  dim=1, keepdim=True)[0] # strong pixels\n",
        "        attn = torch.cat([avg, mx], dim=1)\n",
        "        attn = self.sigmoid(self.conv(attn))\n",
        "        return x * attn\n",
        "\n",
        "class ResConvLSTMwithAttention(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dim=32, patch_size=7, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.patch_size = patch_size\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.input_conv = nn.Conv2d(in_channels, hidden_dim, kernel_size=3, padding=1)\n",
        "        self.bn = nn.BatchNorm2d(hidden_dim)\n",
        "        self.se = SqueezeExcite(hidden_dim)\n",
        "\n",
        "        self.lstm_cell = ConvLSTMCell(hidden_dim, hidden_dim)\n",
        "\n",
        "        self.spatial_attn = SpatialAttention()\n",
        "\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.conv1x1 = nn.Conv2d(hidden_dim, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, T, H, W = x.size()\n",
        "        h1, c1 = torch.zeros(B, self.hidden_dim, H, W, device=x.device), \\\n",
        "               torch.zeros(B, self.hidden_dim, H, W, device=x.device)\n",
        "        h2, c2 = torch.zeros(B, self.hidden_dim, H, W, device=x.device), \\\n",
        "               torch.zeros(B, self.hidden_dim, H, W, device=x.device)\n",
        "\n",
        "        for t in range(T):\n",
        "            x_t = x[:, :, t, :, :]\n",
        "            x_t = self.input_conv(x_t)\n",
        "            x_t = self.bn(x_t)\n",
        "            x_t = F.relu(x_t)\n",
        "            x_t = self.se(x_t)\n",
        "            x_t = self.spatial_attn(x_t)\n",
        "\n",
        "            h, c = self.lstm_cell(x_t, h, c)\n",
        "            h1, c1 = self.lstm1(x_t, h1, c1)      # 1st ConvLSTM\n",
        "            h2, c2 = self.lstm2(h1, h2, c2)      # 2nd ConvLSTM\n",
        "\n",
        "        out = self.global_pool(h2)       # B x hidden_dim x 1 x 1\n",
        "        out = self.conv1x1(out)        # B x 1 x 1 x 1\n",
        "        out = out.view(B)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Pk9ghK1CZ6bV",
      "metadata": {
        "id": "Pk9ghK1CZ6bV"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "Bm3tfcIRVi0P",
      "metadata": {
        "id": "Bm3tfcIRVi0P"
      },
      "outputs": [],
      "source": [
        "class BurnPatchDataset(Dataset):\n",
        "    def __init__(self, file_paths, normalize=True):\n",
        "        self.file_paths = file_paths\n",
        "        self.normalize = normalize\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.file_paths[idx]\n",
        "        data = np.load(path)\n",
        "        x = data[\"x\"][:4]\n",
        "\n",
        "\n",
        "        y = int(data[\"y\"])\n",
        "\n",
        "        if self.normalize:\n",
        "            mean = np.nanmean(x, axis=(0, 1, 2), keepdims=True)\n",
        "            std = np.nanstd(x, axis=(0, 1, 2), keepdims=True) + 1e-6\n",
        "            x = (x - mean) / std\n",
        "\n",
        "        x = np.transpose(x, (3, 0, 1, 2)).astype(np.float32)\n",
        "        return torch.tensor(x), torch.tensor(y, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "C5IAsJOXrOPV",
      "metadata": {
        "id": "C5IAsJOXrOPV"
      },
      "source": [
        "## ResConvLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "0zmLkhmPKUGW",
      "metadata": {
        "id": "0zmLkhmPKUGW"
      },
      "outputs": [],
      "source": [
        "model = ResConvLSTM(in_channels=10, hidden_dim=32, patch_size=15)\n",
        "model = model.cuda() if torch.cuda.is_available() else model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "KR22d6GDg0BC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KR22d6GDg0BC",
        "outputId": "33645acb-6a24-4564-cc5b-fc58a76df957"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "checkpoint = torch.load(MODELS_DIR / \"best_resconvlstm.pt\", map_location=device)  # device = \"cuda\" or \"cpu\"\n",
        "model.load_state_dict(checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ollqRXglrVXg",
      "metadata": {
        "id": "ollqRXglrVXg"
      },
      "source": [
        "## Inference and Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "6Ai-HVLXiaB2",
      "metadata": {
        "id": "6Ai-HVLXiaB2"
      },
      "outputs": [],
      "source": [
        "TEST_DIR = BASE_DIR / \"data\"/ \"test\"\n",
        "\n",
        "\n",
        "grid_df = pd.read_csv(TEST_DIR / \"common_grid_from_burn_area.csv\")\n",
        "\n",
        "gdf = gpd.GeoDataFrame(\n",
        "    grid_df,\n",
        "    geometry=[Point(x, y) for x, y in zip(grid_df.lon, grid_df.lat)],\n",
        "    crs=\"EPSG:4326\"\n",
        ")\n",
        "\n",
        "lat_vals = np.sort(grid_df[\"lat\"].unique())\n",
        "lon_vals = np.sort(grid_df[\"lon\"].unique())\n",
        "\n",
        "n_lat, n_lon = len(lat_vals), len(lon_vals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "Sp9j6yrbD73F",
      "metadata": {
        "id": "Sp9j6yrbD73F"
      },
      "outputs": [],
      "source": [
        "class InferencePatchDataset(Dataset):\n",
        "    def __init__(self, ds_stack, input_vars, patch_size=7, normalize=True):\n",
        "        self.ds_stack = ds_stack\n",
        "        self.input_vars = input_vars\n",
        "        self.patch_size = patch_size\n",
        "        self.normalize = normalize\n",
        "        self.T = ds_stack.sizes[\"time\"]\n",
        "        self.H = ds_stack.sizes[\"lat\"]\n",
        "        self.W = ds_stack.sizes[\"lon\"]\n",
        "        self.half_patch = patch_size // 2\n",
        "\n",
        "\n",
        "        self.inputs = np.stack([\n",
        "            ds_stack[var].values for var in input_vars\n",
        "        ], axis=0)\n",
        "\n",
        "\n",
        "        self.coords = [\n",
        "            (i, j)\n",
        "            for i in range(self.half_patch, self.H - self.half_patch)\n",
        "            for j in range(self.half_patch, self.W - self.half_patch)\n",
        "        ]\n",
        "\n",
        "        if normalize:\n",
        "            self.mean = np.nanmean(self.inputs, axis=(1, 2, 3), keepdims=True)\n",
        "            self.std = np.nanstd(self.inputs, axis=(1, 2, 3), keepdims=True) + 1e-6\n",
        "            self.inputs = (self.inputs - self.mean) / self.std\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.coords)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        i, j = self.coords[idx]\n",
        "        patch = self.inputs[\n",
        "            :,  # all variables\n",
        "            :-1,  # all timesteps\n",
        "            i - self.half_patch : i + self.half_patch + 1,\n",
        "            j - self.half_patch : j + self.half_patch + 1\n",
        "        ]  # shape (V, T, patch, patch)\n",
        "        return torch.tensor(patch.astype(np.float32)), (i, j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "yxISYC2eSCES",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yxISYC2eSCES",
        "outputId": "7bd0512e-a24d-4a4c-9831-615910bd7836"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/danieldominguez/Documents/Code/I_Guide/I_Guide_Team_2/5.2.ResConvLSTM_test.ipynb Cell 14\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldominguez/Documents/Code/I_Guide/I_Guide_Team_2/5.2.ResConvLSTM_test.ipynb#X16sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mfor\u001b[39;00m x, (i_idx, j_idx) \u001b[39min\u001b[39;00m infer_loader:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldominguez/Documents/Code/I_Guide/I_Guide_Team_2/5.2.ResConvLSTM_test.ipynb#X16sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/danieldominguez/Documents/Code/I_Guide/I_Guide_Team_2/5.2.ResConvLSTM_test.ipynb#X16sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     logits \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldominguez/Documents/Code/I_Guide/I_Guide_Team_2/5.2.ResConvLSTM_test.ipynb#X16sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     probs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(logits)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldominguez/Documents/Code/I_Guide/I_Guide_Team_2/5.2.ResConvLSTM_test.ipynb#X16sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(probs)):\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1786\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
            "\u001b[1;32m/Users/danieldominguez/Documents/Code/I_Guide/I_Guide_Team_2/5.2.ResConvLSTM_test.ipynb Cell 14\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldominguez/Documents/Code/I_Guide/I_Guide_Team_2/5.2.ResConvLSTM_test.ipynb#X16sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     x_t \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(x_t)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldominguez/Documents/Code/I_Guide/I_Guide_Team_2/5.2.ResConvLSTM_test.ipynb#X16sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     x_t \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mse(x_t)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/danieldominguez/Documents/Code/I_Guide/I_Guide_Team_2/5.2.ResConvLSTM_test.ipynb#X16sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     h, c \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm_cell(x_t, h, c)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldominguez/Documents/Code/I_Guide/I_Guide_Team_2/5.2.ResConvLSTM_test.ipynb#X16sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mglobal_pool(h)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldominguez/Documents/Code/I_Guide/I_Guide_Team_2/5.2.ResConvLSTM_test.ipynb#X16sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1x1(out)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1786\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
            "\u001b[1;32m/Users/danieldominguez/Documents/Code/I_Guide/I_Guide_Team_2/5.2.ResConvLSTM_test.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldominguez/Documents/Code/I_Guide/I_Guide_Team_2/5.2.ResConvLSTM_test.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, h_prev, c_prev):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldominguez/Documents/Code/I_Guide/I_Guide_Team_2/5.2.ResConvLSTM_test.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     combined \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([x, h_prev], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/danieldominguez/Documents/Code/I_Guide/I_Guide_Team_2/5.2.ResConvLSTM_test.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     conv_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv(combined)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldominguez/Documents/Code/I_Guide/I_Guide_Team_2/5.2.ResConvLSTM_test.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     cc_i, cc_f, cc_o, cc_g \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mchunk(conv_output, \u001b[39m4\u001b[39m, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldominguez/Documents/Code/I_Guide/I_Guide_Team_2/5.2.ResConvLSTM_test.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     i \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(cc_i)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1786\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/conv.py:548\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 548\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_conv_forward(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/conv.py:543\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    532\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(\n\u001b[1;32m    533\u001b[0m         F\u001b[39m.\u001b[39mpad(\n\u001b[1;32m    534\u001b[0m             \u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups,\n\u001b[1;32m    542\u001b[0m     )\n\u001b[0;32m--> 543\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(\n\u001b[1;32m    544\u001b[0m     \u001b[39minput\u001b[39m, weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups\n\u001b[1;32m    545\u001b[0m )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "csv_files = sorted(glob.glob(str(TEST_DIR / \"daily_csv\" / \"*.csv\")))\n",
        "columns = ['land_cover', 'dem', 't2m', 'd2m', 'u10', 'v10', 'tp', 'swvl1', 'sp', 'burn']\n",
        "input_vars = columns\n",
        "T = 5\n",
        "prob_threshold = 0.975\n",
        "all_five_probs = []\n",
        "\n",
        "for i in range(0, 5):\n",
        "  # --- Pick a sequence of 5 days to predict the last day ---\n",
        "  stack = []\n",
        "  dates = []\n",
        "\n",
        "  for j in range(T):\n",
        "      df = pd.read_csv(csv_files[i + j])\n",
        "      date = csv_files[i + j].split(\"/\")[-1].replace(\".csv\", \"\")\n",
        "      dates.append(date)\n",
        "\n",
        "      var_dict = {}\n",
        "      for col in columns:\n",
        "          arr = df[col].values.reshape(n_lat, n_lon)\n",
        "          var_dict[col] = ([\"lat\", \"lon\"], arr)\n",
        "\n",
        "      ds_day = xr.Dataset(data_vars=var_dict, coords={\"lat\": lat_vals, \"lon\": lon_vals})\n",
        "      stack.append(ds_day)\n",
        "\n",
        "  ds_stack = xr.concat(stack, dim=\"time\")\n",
        "  ds_stack = ds_stack.assign_coords(time=pd.to_datetime(dates))\n",
        "\n",
        "  input_vars = columns\n",
        "  patch_size = 15\n",
        "\n",
        "  infer_ds = InferencePatchDataset(ds_stack, input_vars, patch_size=patch_size)\n",
        "\n",
        "  infer_loader = DataLoader(infer_ds, batch_size=64, shuffle=False)\n",
        "\n",
        "  # model.eval()\n",
        "  all_probs = np.zeros((ds_stack.sizes[\"lat\"], ds_stack.sizes[\"lon\"]))\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for x, (i_idx, j_idx) in infer_loader:\n",
        "          x = x.to(device)\n",
        "          logits = model(x)\n",
        "          probs = torch.sigmoid(logits).cpu().numpy().squeeze()\n",
        "\n",
        "          for b in range(len(probs)):\n",
        "              i, j = i_idx[b].item(), j_idx[b].item()\n",
        "              all_probs[i, j] = probs[b]\n",
        "\n",
        "  all_five_probs.append(all_probs)\n",
        "\n",
        "  test_binary_image = (all_probs > prob_threshold).astype(int)\n",
        "  burn_truth_image = ds_stack['burn'].isel(time=-1).values\n",
        "  test_binary = np.reshape((all_probs > prob_threshold).astype(int), -1)\n",
        "  burn_truth = np.reshape(ds_stack['burn'].isel(time=-1).values, -1)\n",
        "\n",
        "  if np.sum(test_binary) > 5:\n",
        "\n",
        "    print(\"Accuracy:\", accuracy_score(burn_truth, test_binary))\n",
        "    print(\"Precision:\", precision_score(burn_truth, test_binary))\n",
        "    print(\"Recall:\", recall_score(burn_truth, test_binary))\n",
        "    print(\"F1 Score:\", f1_score(burn_truth, test_binary))\n",
        "\n",
        "    mask = burn_truth_image > prob_threshold\n",
        "\n",
        "    # Find connected components\n",
        "    structure = np.ones((3, 3))  # 8-connectivity\n",
        "    labeled_array, num_features = label(mask, structure=structure)\n",
        "\n",
        "    # Count pixels in each component\n",
        "    sizes = np.bincount(labeled_array.ravel())\n",
        "    sizes[0] = 0  # background = 0\n",
        "\n",
        "    # Find the label of the largest component\n",
        "    largest_label = sizes.argmax()\n",
        "\n",
        "    # Mask to keep only the largest cluster\n",
        "    largest_cluster_mask = labeled_array == largest_label\n",
        "\n",
        "    # Get bounding box of this cluster\n",
        "    rows, cols = np.where(largest_cluster_mask)\n",
        "\n",
        "    center_row = int(np.mean(rows))\n",
        "    center_col = int(np.mean(cols))\n",
        "\n",
        "    crop_size = 200\n",
        "    half_crop = crop_size // 2\n",
        "\n",
        "    # Ensure the window stays within bounds\n",
        "    row_min = max(center_row - half_crop, 0)\n",
        "    row_max = min(center_row + half_crop, all_probs.shape[0])\n",
        "    col_min = max(center_col - half_crop, 0)\n",
        "    col_max = min(center_col + half_crop, all_probs.shape[1])\n",
        "\n",
        "    burn_prob_crop = all_probs[row_min:row_max, col_min:col_max]\n",
        "    burn_pred_crop = test_binary_image[row_min:row_max, col_min:col_max].astype(float)\n",
        "    burn_true_crop = burn_truth_image[row_min:row_max, col_min:col_max].astype(float)\n",
        "\n",
        "    lat_crop = lat_vals[row_min:row_max] #lat_vals = np.sort(grid_df[\"lat\"].unique())\n",
        "                                    #lon_vals = np.sort(grid_df[\"lon\"].unique())\n",
        "    lon_crop = lon_vals[col_min:col_max]\n",
        "\n",
        "    fig = plt.figure(figsize=(16, 5), constrained_layout=True)\n",
        "    gs = gridspec.GridSpec(1, 4, width_ratios=[1, 1, 1, 0.05], figure=fig)\n",
        "\n",
        "    # Create first axis normally\n",
        "    axs0 = fig.add_subplot(gs[0])\n",
        "    # Share y with axs0\n",
        "    axs1 = fig.add_subplot(gs[1], sharey=axs0)\n",
        "    axs2 = fig.add_subplot(gs[2], sharey=axs0)\n",
        "    axs = [axs0, axs1, axs2]\n",
        "\n",
        "    # Colorbar axis\n",
        "    cax = fig.add_subplot(gs[3])\n",
        "\n",
        "    vmin, vmax = 0.0, 1.0\n",
        "\n",
        "    # Burn probability\n",
        "    im0 = axs[0].imshow(burn_prob_crop, cmap='Reds', vmin=vmin, vmax=vmax,\n",
        "                        extent=[lon_crop[0], lon_crop[-1], lat_crop[-1], lat_crop[0]])\n",
        "    axs[0].set_title(\"Burn Probability\")\n",
        "    axs[0].set_xlabel(\"Longitude\")\n",
        "    axs[0].set_ylabel(\"Latitude\")\n",
        "\n",
        "    reds = plt.colormaps['Reds'].copy()\n",
        "    reds.set_bad(color='white')\n",
        "\n",
        "    # Predicted burn\n",
        "    burn_pred_crop[burn_pred_crop == 0] = np.nan\n",
        "    im1 = axs[1].imshow(burn_pred_crop, cmap=reds, vmin=vmin, vmax=vmax,\n",
        "                        extent=[lon_crop[0], lon_crop[-1], lat_crop[-1], lat_crop[0]],interpolation='nearest')\n",
        "    axs[1].set_title(\"Predicted Burn\")\n",
        "    axs[1].set_xlabel(\"Longitude\")\n",
        "\n",
        "    # Ground truth\n",
        "    burn_true_crop[burn_true_crop == 0] = np.nan\n",
        "    im2 = axs[2].imshow(burn_true_crop, cmap=reds, vmin=vmin, vmax=vmax,\n",
        "                        extent=[lon_crop[0], lon_crop[-1], lat_crop[-1], lat_crop[0]],interpolation='nearest')\n",
        "    axs[2].set_title(\"Ground Truth Burn\")\n",
        "    axs[2].set_xlabel(\"Longitude\")\n",
        "\n",
        "    # Shared colorbar\n",
        "    cbar = fig.colorbar(im2, cax=cax)\n",
        "    cbar.set_label(\"Value (0–1)\")\n",
        "\n",
        "    fig.suptitle(f\"Burn Prediction vs Ground Truth on 2024-06-{15+i} (zoomed-in view)\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26096bc4",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
